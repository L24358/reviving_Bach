{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3321b34a",
   "metadata": {},
   "source": [
    "# Let's generate some music!\n",
    "\n",
    "1. Run through the basic set up code blocks.\n",
    "2. Load the model, reconstruct or generate new music.\n",
    "\n",
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b09591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import muse.supplier as spr\n",
    "import muse.processor2 as pcr\n",
    "import muse.model2 as mdl\n",
    "import muse.trainer as trn\n",
    "import muse.visualizer as vis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85235d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Hyperparameters ===== ###\n",
    "\n",
    "instrument = 'Piano'\n",
    "filepath = \"./../input/haydn/\"\n",
    "song_len = 200*4\n",
    "stride = 200\n",
    "device = trn.get_device()\n",
    "\n",
    "seed_load = 592643464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cd20e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Data Preprocessing ===== ###\n",
    "\n",
    "all_midis, filenames = pcr.get_midis(filepath) # load all .midi files\n",
    "Corpus, instru2corpus = pcr.get_notes_batch(all_midis) # extract all notes and sort by instrument\n",
    "Corpus, fmap, rmap = pcr.get_map(Corpus) # get forward-map and reverse-map from corpus\n",
    "instru2corpus = pcr.remove_short(instru2corpus) # remove songs that are too short\n",
    "instru2corpus = pcr.upsample_batch(instru2corpus) # upsample notes according to multiples of duration\n",
    "\n",
    "X_train_melody, X_val_melody, X_train_offset, X_val_offset = pcr.train_test_split(instru2corpus, instrument, fmap, song_len, stride,\\\n",
    "                                                                                  seed=seed_load, process='center')\n",
    "X_train_melody, X_val_melody = pcr.batchify(X_train_melody), pcr.batchify(X_val_melody) # reshape and turn into tensor\n",
    "X_train_offset, X_val_offset = pcr.batchify(X_train_offset), pcr.batchify(X_val_offset) # reshape and turn into tensor\n",
    "\n",
    "classes = len(set(Corpus)) # get number of unique keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ac548",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52b1f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn_varautoencoder(\n",
       "  (encoder): cnn_varencoder(\n",
       "    (conv1): Conv1d(1, 16, kernel_size=(21,), stride=(1,))\n",
       "    (conv21): Conv1d(16, 4, kernel_size=(11,), stride=(1,))\n",
       "    (conv22): Conv1d(16, 4, kernel_size=(11,), stride=(1,))\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (relu): ReLU()\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=760, out_features=20, bias=True)\n",
       "  )\n",
       "  (decoder): cnn_vardecoder(\n",
       "    (tconv1): ConvTranspose1d(4, 16, kernel_size=(11,), stride=(1,))\n",
       "    (tconv2): ConvTranspose1d(16, 1, kernel_size=(31,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "    (sigmoid): Sigmoid()\n",
       "    (linear): Linear(in_features=20, out_features=3040, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ===== Load model ===== ###\n",
    "\n",
    "model1 = mdl.cnn_varautoencoder(1, 4, 61, std=1.0)\n",
    "model4_mel = trn.load_model('vae3_melody_CE', model1, device)[0]\n",
    "model4_mel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be716a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Reconstruction ===== ###\n",
    "\n",
    "for idx in range(len(X_train_melody)):\n",
    "    pcr.gen_reconstruction(model4_mel, None, X_train_melody, X_train_offset, rmap, base=1, idx=idx) # idx = 80, 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66cc93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Generation ===== ###\n",
    "\n",
    "mus = []\n",
    "for song in X_train_melody:\n",
    "    mu, logvar = model4_mel.encoder(song)\n",
    "    mus.append(mu.view(-1).detach().numpy())\n",
    "\n",
    "mu_avg = np.mean(np.array(mus), axis=0)\n",
    "cov_avg = np.cov(np.array(mus), rowvar=False)\n",
    "\n",
    "for i in range(20):\n",
    "    _ = pcr.gen_generation_vae(mu_avg, cov_avg, model4_mel, rmap, fname='new_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287aab51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
