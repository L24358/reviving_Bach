{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c15628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import muse.supplier as spr\n",
    "import muse.processor2 as pcr\n",
    "import muse.model2 as mdl\n",
    "import muse.trainer as trn\n",
    "import muse.visualizer as vis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f273617",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument = 'Piano'\n",
    "filepath = \"./../input/haydn/\"\n",
    "song_len = 200*1\n",
    "stride = 200\n",
    "batch_size = 1\n",
    "latent_size = 20\n",
    "device = trn.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff78bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Data Preprocessing ===== ###\n",
    "\n",
    "seed_load = np.random.randint(0,999999999)\n",
    "seed_load = 592643464 # set to seed that works\n",
    "\n",
    "all_midis, filenames = pcr.get_midis(filepath) # load all .midi files\n",
    "Corpus, instru2corpus = pcr.get_notes_batch(all_midis) # extract all notes and sort by instrument\n",
    "Corpus, fmap, rmap = pcr.get_map(Corpus) # get forward-map and reverse-map from corpus\n",
    "instru2corpus = pcr.remove_short(instru2corpus) # remove songs that are too short\n",
    "\n",
    "X_train_melody, X_val_melody, X_train_offset, X_val_offset = pcr.train_test_split(instru2corpus, instrument, fmap, song_len, stride,\\\n",
    "                                                                                  seed=seed_load, process='center')\n",
    "X_train_melody, X_val_melody = pcr.batchify(X_train_melody), pcr.batchify(X_val_melody) # reshape and turn into tensor\n",
    "X_train_offset, X_val_offset = pcr.batchify(X_train_offset), pcr.batchify(X_val_offset) # reshape and turn into tensor\n",
    "\n",
    "classes = len(set(Corpus)) # get number of unique keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54d9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mdl.cnn_varautoencoder(1, song_len//200, classes)\n",
    "G = trn.load_model('vae4_melody_CE', model, device)[0].decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed7ec270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_generation_gan(model, rmap, classes, base=1, fname='new'):\n",
    "    sample_latent = lambda batch_size, latent_size: torch.FloatTensor(batch_size, latent_size).uniform_(0, classes)\n",
    "    latent = sample_latent(1, latent_size).type(torch.FloatTensor)\n",
    "    new_train_melody1 = model(latent)\n",
    "    scale = torch.max(new_train_melody1, dim=-1)[0].item()\n",
    "    new_train_melody1 = new_train_melody1.multiply(classes)/scale\n",
    "    new_train_melody2 = pcr.rmap_safe(rmap, new_train_melody1.view(-1).detach().numpy())\n",
    "    const_offset = np.arange(len(new_train_melody2))\n",
    "    \n",
    "    pcr.gen_stream(new_train_melody2, const_offset, base=base, output=True,\n",
    "               fname=fname)\n",
    "    return new_train_melody1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66f53d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    _ = gen_generation_gan(G, rmap, classes, base=1, fname='new_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5a13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
