{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e5bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import muse.supplier as spr\n",
    "import muse.processor2 as pcr\n",
    "import muse.model2 as mdl\n",
    "import muse.trainer as trn\n",
    "import muse.visualizer as vis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0493a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Hyperparameters ===== ###\n",
    "\n",
    "instrument = 'Piano'\n",
    "filepath = \"./../input/beeth/\"\n",
    "song_len = 200\n",
    "stride = 200\n",
    "device = trn.get_device()\n",
    "\n",
    "seed_load = 592643464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17673d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===== Data Preprocessing ===== ###\n",
    "\n",
    "seed_load = np.random.randint(0,999999999)\n",
    "seed_load = 592643464 # set to seed that works\n",
    "\n",
    "all_midis, filenames = pcr.get_midis(filepath) # load all .midi files\n",
    "Corpus, instru2corpus = pcr.get_notes_batch(all_midis) # extract all notes and sort by instrument\n",
    "\n",
    "Corpus, fmap, rmap = pcr.get_map(Corpus) # get forward-map and reverse-map from corpus\n",
    "Corpus2, fmap2, rmap2 = pcr.get_map_offset_v2(instru2corpus, instrument)\n",
    "instru2corpus = pcr.remove_short(instru2corpus) # remove songs that are too short\n",
    "\n",
    "X_train_melody, X_val_melody, X_train_offset, X_val_offset = pcr.train_test_split(instru2corpus, instrument, fmap, song_len, stride,\\\n",
    "                                                                                  seed=seed_load, process='center')\n",
    "X_train_melody, X_val_melody = pcr.batchify(X_train_melody), pcr.batchify(X_val_melody) # reshape and turn into tensor\n",
    "X_train_offset, X_val_offset = pcr.batchify(X_train_offset), pcr.batchify(X_val_offset) # reshape and turn into tensor\n",
    "\n",
    "X_train_offset = pcr.fmap_offset(X_train_offset, fmap2, song_len)\n",
    "X_val_offset = pcr.fmap_offset(X_val_offset, fmap2, song_len)\n",
    "\n",
    "fmap_j, rmap_j = pcr.get_joint_map(fmap, fmap2)\n",
    "classes_j = len(set(fmap_j.keys()))\n",
    "\n",
    "X_train_joint = pcr.zip_(X_train_melody, X_train_offset, rmap, rmap2, fmap_j)\n",
    "X_val_joint = pcr.zip_(X_val_melody, X_val_offset, rmap, rmap2, fmap_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e95793d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn_varautoencoder(\n",
       "  (encoder): cnn_varencoder(\n",
       "    (conv1): Conv1d(1, 16, kernel_size=(21,), stride=(1,))\n",
       "    (conv21): Conv1d(16, 4, kernel_size=(11,), stride=(1,))\n",
       "    (conv22): Conv1d(16, 4, kernel_size=(11,), stride=(1,))\n",
       "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (relu): ReLU()\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=160, out_features=20, bias=True)\n",
       "  )\n",
       "  (decoder): cnn_vardecoder(\n",
       "    (tconv1): ConvTranspose1d(4, 16, kernel_size=(11,), stride=(1,))\n",
       "    (tconv2): ConvTranspose1d(16, 1, kernel_size=(31,), stride=(1,))\n",
       "    (relu): ReLU()\n",
       "    (sigmoid): Sigmoid()\n",
       "    (linear): Linear(in_features=20, out_features=640, bias=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ===== Load model ===== ###\n",
    "\n",
    "model1 = mdl.cnn_varautoencoder(1, 1, classes_j, std=1.0)\n",
    "model6 = trn.load_model('vae6_CE', model1, device)[0]\n",
    "model6.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "116e83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 80\n",
    "base = 12\n",
    "fname = 'temp'\n",
    "\n",
    "if idx == None: idx = np.random.randint(0, len(X_train_joint))\n",
    "recons = model6(X_train_joint[idx])[0].squeeze().detach().numpy()*20.0\n",
    "melody, duration = pcr.rmap_safe(rmap_j, recons).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d05b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = [0]\n",
    "\n",
    "cumulation = 0\n",
    "for d in duration:\n",
    "    cumulation += float(d)\n",
    "    offset.append(cumulation)\n",
    "offset = np.array(offset)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "692fa763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.Stream 0x1efc94e7670>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcr.gen_stream(melody, offset, base=base, output=True, fname=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0871bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
